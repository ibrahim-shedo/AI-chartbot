{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895b3ac1-1dc3-4fc1-9b8c-a5d7a15622c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ibrez\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk tensorflow scikit-learn\n",
    "!pip install nltk tensorflow scikit-learn json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db837570-89b3-475d-9ea7-757f85e12bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ibrez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ibrez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am an AI chatbot. I can also learn new things! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Chatbot: Hi! How’s your day going?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I'm good do you know me \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Chatbot: I don’t seem to remember yet. What should I call you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  call me shedoh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Chatbot: Great, {name}! I’ll try to remember that.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  okey what is my name now \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Chatbot: I don't know how to respond to that. How should I reply?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Teach me:  how are you \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Got it! I’ll remember this for future conversations.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who are you \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Chatbot: I’m an AI chatbot, here to assist you!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load or Create Memory (JSON-based storage)\n",
    "MEMORY_FILE = \"chatbot_memory.json\"\n",
    "\n",
    "if os.path.exists(MEMORY_FILE):\n",
    "    with open(MEMORY_FILE, \"r\") as file:\n",
    "        chatbot_memory = json.load(file)\n",
    "else:\n",
    "    chatbot_memory = {\"intents\": []}\n",
    "\n",
    "# Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preprocesses text by:\n",
    "    - Lowercasing\n",
    "    - Removing special characters, punctuation, and extra spaces\n",
    "    - Tokenizing and lemmatizing words\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])  # Lemmatization\n",
    "    return text\n",
    "\n",
    "# Load predefined intents and add learned responses\n",
    "# Predefined intents with additional user identity recognition\n",
    "predefined_intents = {\n",
    "    \"intents\": [\n",
    "        # Greetings\n",
    "        {\n",
    "            \"tag\": \"greeting\",\n",
    "            \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"Good morning\", \"Good afternoon\", \"Howdy\"],\n",
    "            \"responses\": [\"Hello! How can I assist you?\", \"Hey there! What’s on your mind?\", \"Hi! How’s your day going?\"]\n",
    "        },\n",
    "\n",
    "        # Farewell\n",
    "        {\n",
    "            \"tag\": \"goodbye\",\n",
    "            \"patterns\": [\"Bye\", \"Goodbye\", \"See you\", \"Later\", \"Catch you later\"],\n",
    "            \"responses\": [\"Goodbye! Have a great day!\", \"See you soon!\", \"Take care!\"]\n",
    "        },\n",
    "\n",
    "        # Thank You\n",
    "        {\n",
    "            \"tag\": \"thanks\",\n",
    "            \"patterns\": [\"Thanks\", \"Thank you\", \"Appreciate it\", \"Thanks a lot\"],\n",
    "            \"responses\": [\"You're welcome!\", \"No problem!\", \"Glad I could help!\"]\n",
    "        },\n",
    "\n",
    "        # Asking About the Bot\n",
    "        {\n",
    "            \"tag\": \"bot_info\",\n",
    "            \"patterns\": [\"Who are you?\", \"What is your name?\", \"Are you a bot?\"],\n",
    "            \"responses\": [\"I’m an AI chatbot, here to assist you!\", \"I’m your virtual assistant!\", \"I am an AI created to help with various tasks.\"]\n",
    "        },\n",
    "\n",
    "        # User Identity Recognition\n",
    "        {\n",
    "            \"tag\": \"user_identity\",\n",
    "            \"patterns\": [\"What is my name?\", \"Who am I?\", \"Do you know me?\", \"Do you remember me?\"],\n",
    "            \"responses\": [\"I might not remember everything, but I can learn! What’s your name?\", \n",
    "                          \"I’d love to know your name! Can you tell me?\", \n",
    "                          \"I don’t seem to remember yet. What should I call you?\"]\n",
    "        },\n",
    "\n",
    "        # Saving User's Name\n",
    "        {\n",
    "            \"tag\": \"save_name\",\n",
    "            \"patterns\": [\"My name is *\", \"Call me *\", \"I am *\"],\n",
    "            \"responses\": [\"Nice to meet you, {name}!\", \"Great, {name}! I’ll try to remember that.\", \"Cool, {name}! How can I assist you today?\"]\n",
    "        },\n",
    "\n",
    "        # Weather Inquiry\n",
    "        {\n",
    "            \"tag\": \"weather\",\n",
    "            \"patterns\": [\"What's the weather like?\", \"How's the weather?\", \"Tell me the weather\"],\n",
    "            \"responses\": [\"I don’t have live weather updates yet, but you can check a weather website!\", \"I can’t fetch weather data right now, but you can try Google Weather!\"]\n",
    "        },\n",
    "\n",
    "        # Time Inquiry\n",
    "        {\n",
    "            \"tag\": \"time\",\n",
    "            \"patterns\": [\"What time is it?\", \"Can you tell me the time?\", \"Current time please\"],\n",
    "            \"responses\": [\"I can't check the time yet, but you can try asking your device!\", \"Your phone or computer should have the time displayed.\"]\n",
    "        },\n",
    "\n",
    "        # Learning Capability\n",
    "        {\n",
    "            \"tag\": \"learning\",\n",
    "            \"patterns\": [\"Can you learn?\", \"Do you remember things?\", \"How do you learn?\"],\n",
    "            \"responses\": [\"I can remember new things if you teach me!\", \"Yes, I can store new knowledge and recall it later.\"]\n",
    "        },\n",
    "\n",
    "        # Hobbies & Fun\n",
    "        {\n",
    "            \"tag\": \"hobbies\",\n",
    "            \"patterns\": [\"What do you do for fun?\", \"Do you have hobbies?\", \"Do you like games?\"],\n",
    "            \"responses\": [\"I enjoy chatting with people like you!\", \"I don’t have hobbies, but I can recommend fun things to do!\", \"Talking to people is my favorite thing!\"]\n",
    "        },\n",
    "\n",
    "        # Advice & Motivation\n",
    "        {\n",
    "            \"tag\": \"motivation\",\n",
    "            \"patterns\": [\"I feel sad\", \"I need motivation\", \"Can you inspire me?\"],\n",
    "            \"responses\": [\"You are stronger than you think! Keep pushing forward!\", \"Believe in yourself, and great things will happen!\", \"Tough times never last, but tough people do!\"]\n",
    "        },\n",
    "\n",
    "        # Jokes\n",
    "        {\n",
    "            \"tag\": \"joke\",\n",
    "            \"patterns\": [\"Tell me a joke\", \"Make me laugh\", \"Do you know jokes?\"],\n",
    "            \"responses\": [\n",
    "                \"Why don’t skeletons fight each other? Because they don’t have the guts!\",\n",
    "                \"What did one ocean say to the other? Nothing, they just waved!\",\n",
    "                \"Why was the math book sad? Because it had too many problems!\"\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        # Unknown\n",
    "        {\n",
    "            \"tag\": \"unknown\",\n",
    "            \"patterns\": [],\n",
    "            \"responses\": [\"I’m not sure how to respond to that.\", \"Can you rephrase?\", \"I don’t know yet, but you can teach me!\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Merge chatbot memory with predefined intents\n",
    "for learned_intent in chatbot_memory[\"intents\"]:\n",
    "    predefined_intents[\"intents\"].append(learned_intent)\n",
    "\n",
    "# Prepare training data\n",
    "patterns = []\n",
    "labels = []\n",
    "responses_dict = {}\n",
    "\n",
    "for intent in predefined_intents[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        processed_pattern = preprocess(pattern)\n",
    "        patterns.append(processed_pattern)\n",
    "        labels.append(intent[\"tag\"])\n",
    "    responses_dict[intent[\"tag\"]] = intent[\"responses\"]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert text to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(patterns).toarray()\n",
    "y_train = np.array(labels_encoded)\n",
    "\n",
    "# Define neural network model\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(X_train.shape[1],), activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(len(set(labels)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "\n",
    "# Function to add new knowledge\n",
    "def learn_new_knowledge(user_input, user_response):\n",
    "    # Save new knowledge\n",
    "    new_intent = {\n",
    "        \"tag\": f\"learned_{len(chatbot_memory['intents'])}\",\n",
    "        \"patterns\": [user_input],\n",
    "        \"responses\": [user_response]\n",
    "    }\n",
    "    chatbot_memory[\"intents\"].append(new_intent)\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(MEMORY_FILE, \"w\") as file:\n",
    "        json.dump(chatbot_memory, file, indent=4)\n",
    "\n",
    "    print(\"Chatbot: Got it! I’ll remember this for future conversations.\")\n",
    "\n",
    "# Function to get chatbot response\n",
    "def get_response(user_input):\n",
    "    processed_input = preprocess(user_input)\n",
    "    user_tfidf = vectorizer.transform([processed_input]).toarray()\n",
    "\n",
    "    # Predict intent using trained model\n",
    "    prediction = model.predict(user_tfidf)[0]\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    confidence = prediction[predicted_index]\n",
    "\n",
    "    # If confidence is high, use learned response\n",
    "    if confidence > 0.5:\n",
    "        tag = label_encoder.inverse_transform([predicted_index])[0]\n",
    "        return random.choice(responses_dict[tag])\n",
    "    else:\n",
    "        return None  # Unknown response, ask user for learning\n",
    "\n",
    "# Chat function with learning capability\n",
    "def chat():\n",
    "    print(\"Hello! I am an AI chatbot. I can also learn new things! Type 'exit' to end the conversation.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"bye\", \"quit\"]:\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        response = get_response(user_input)\n",
    "        \n",
    "        if response:\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        else:\n",
    "            # Learn new information\n",
    "            print(\"Chatbot: I don't know how to respond to that. How should I reply?\")\n",
    "            user_response = input(\"Teach me: \")\n",
    "            learn_new_knowledge(user_input, user_response)\n",
    "\n",
    "# Start chatbot\n",
    "chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b774c0b-c064-4059-aee8-a590d2a6bf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
